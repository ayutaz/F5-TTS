# ReStyle-TTS ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©³ç´°

> **å®Ÿè£…çŠ¶æ³**: Phase 1 (DCFG) âœ… å®Œäº† / Phase 2 (Style LoRA) âœ… å®Œäº†
>
> è©³ç´°ã¯ [IMPLEMENTATION_PLAN.md](./IMPLEMENTATION_PLAN.md) ã‚’å‚ç…§

## 1. è«–æ–‡æ¦‚è¦

**ReStyle-TTS: Relative and Continuous Style Control for Zero-Shot Speech Synthesis**
- arXiv:2601.03632v1 (2026å¹´1æœˆ7æ—¥)
- è‘—è€…: Haitao Li et al. (Zhejiang University, Shanghai Jiao Tong University)

### å•é¡Œè¨­å®š
ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆTTSã§ã¯å‚ç…§éŸ³å£°ã®ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆéŸ»å¾‹ãƒ»æ„Ÿæƒ…ï¼‰ãŒç”ŸæˆéŸ³å£°ã«å¼·ãå½±éŸ¿ã—ã€æŸ”è»Ÿãªã‚¹ã‚¿ã‚¤ãƒ«åˆ¶å¾¡ãŒå›°é›£ã€‚

### è§£æ±ºç­–
3ã¤ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã‚ˆã‚‹æ®µéšçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ:
1. **DCFG**: å‚ç…§éŸ³å£°ã¸ã®ä¾å­˜ã‚’æ¸›ã‚‰ã™
2. **Style LoRA + OLoRA**: æ˜ç¤ºçš„ã§é€£ç¶šçš„ãªã‚¹ã‚¿ã‚¤ãƒ«åˆ¶å¾¡
3. **TCO**: éŸ³è‰²åŠ£åŒ–ã‚’è£œå„Ÿ

---

## 2. F5-TTS ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«æ§‹é€ 

### 2.1 å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CFM ã‚¯ãƒ©ã‚¹                           â”‚
â”‚  (src/f5_tts/model/cfm.py)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  MelSpec    â”‚    â”‚ Transformer â”‚    â”‚  ODE Solver â”‚     â”‚
â”‚  â”‚  å¤‰æ›       â”‚ -> â”‚   (DiT)     â”‚ -> â”‚ (odeint)    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 DiT (Diffusion Transformer) æ§‹é€ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/f5_tts/model/backbones/dit.py`

```
DiT
â”œâ”€â”€ text_embed: TextEmbedding
â”‚   â”œâ”€â”€ nn.Embedding(vocab_size, text_dim)
â”‚   â””â”€â”€ ConvNeXtV2Block Ã— conv_layers (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
â”‚
â”œâ”€â”€ input_embed: InputEmbedding
â”‚   â”œâ”€â”€ proj: nn.Linear(mel_dim*2 + text_dim, dim)
â”‚   â””â”€â”€ conv_pos_embed: ConvPositionEmbedding
â”‚
â”œâ”€â”€ rotary_embed: RotaryEmbedding
â”‚
â”œâ”€â”€ time_embed: TimestepEmbedding
â”‚   â””â”€â”€ time_mlp: nn.Sequential(Linear, SiLU, Linear)
â”‚
â”œâ”€â”€ transformer_blocks: nn.ModuleList
â”‚   â””â”€â”€ DiTBlock Ã— depth (22 layers)
â”‚       â”œâ”€â”€ attn_norm: AdaLayerNorm
â”‚       â”‚   â””â”€â”€ linear: nn.Linear(dim, dim*6)
â”‚       â”œâ”€â”€ attn: Attention
â”‚       â”‚   â”œâ”€â”€ to_q: nn.Linear(dim, inner_dim)
â”‚       â”‚   â”œâ”€â”€ to_k: nn.Linear(dim, inner_dim)
â”‚       â”‚   â”œâ”€â”€ to_v: nn.Linear(dim, inner_dim)
â”‚       â”‚   â””â”€â”€ to_out: nn.Linear(inner_dim, dim)
â”‚       â””â”€â”€ ff: FeedForward
â”‚           â”œâ”€â”€ ff[0]: nn.Linear(dim, inner_dim)
â”‚           â””â”€â”€ ff[2]: nn.Linear(inner_dim, dim)
â”‚
â”œâ”€â”€ norm_out: RMSNorm
â””â”€â”€ proj_out: nn.Linear(dim, mel_dim)
```

### 2.3 ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (F5TTS_v1_Base)

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å€¤ |
|-----------|-----|
| dim | 1024 |
| depth | 22 |
| heads | 16 |
| dim_head | 64 |
| ff_mult | 2 |
| text_dim | 512 |
| mel_dim (n_mel_channels) | 100 |
| conv_layers | 4 |

### 2.4 ç·šå½¢å±¤ã®ç·æ•°

1ãƒ–ãƒ­ãƒƒã‚¯ã‚ãŸã‚Š:
- AdaLayerNorm.linear: 1
- Attention (to_q, to_k, to_v, to_out): 4
- FeedForward: 2
- **åˆè¨ˆ**: 7å±¤/ãƒ–ãƒ­ãƒƒã‚¯ Ã— 22ãƒ–ãƒ­ãƒƒã‚¯ = **154å±¤**

ãã®ä»–:
- InputEmbedding.proj: 1
- TimestepEmbedding: 2
- proj_out: 1
- TextEmbeddingå†…: è¤‡æ•°

---

## 3. ç¾åœ¨ã®CFGå®Ÿè£…

### 3.1 è¨“ç·´æ™‚ã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `cfm.py:286-296`

```python
# ãƒ‰ãƒ­ãƒƒãƒ—ç¢ºç‡
audio_drop_prob = 0.3  # å‚ç…§éŸ³å£°ã‚’ãƒ‰ãƒ­ãƒƒãƒ—
cond_drop_prob = 0.2   # ä¸¡æ–¹ï¼ˆéŸ³å£°+ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’ãƒ‰ãƒ­ãƒƒãƒ—

# è¨“ç·´æ™‚ã®é©ç”¨
drop_audio_cond = random() < self.audio_drop_prob
if random() < self.cond_drop_prob:
    drop_audio_cond = True
    drop_text = True
else:
    drop_text = False
```

### 3.2 æ¨è«–æ™‚ã®CFG

**ãƒ•ã‚¡ã‚¤ãƒ«**: `cfm.py:160-191`

```python
def fn(t, x):
    if cfg_strength < 1e-5:
        # CFGãªã—: æ¡ä»¶ä»˜ãäºˆæ¸¬ã®ã¿
        pred = self.transformer(x, cond, text, t,
                                drop_audio_cond=False, drop_text=False)
        return pred

    # CFGã‚ã‚Š: ãƒãƒƒãƒé€£çµã§åŠ¹ç‡åŒ–
    pred_cfg = self.transformer(x, cond, text, t, cfg_infer=True)
    pred, null_pred = torch.chunk(pred_cfg, 2, dim=0)
    return pred + (pred - null_pred) * cfg_strength
```

### 3.3 DiTã§ã®cfg_inferå‡¦ç†

**ãƒ•ã‚¡ã‚¤ãƒ«**: `dit.py:296-310`

```python
if cfg_infer:
    # æ¡ä»¶ä»˜ãã¨ç„¡æ¡ä»¶ã‚’é€£çµ
    x_cond = self.get_input_embed(x, cond, text,
                                   drop_audio_cond=False, drop_text=False)
    x_uncond = self.get_input_embed(x, cond, text,
                                     drop_audio_cond=True, drop_text=True)
    x = torch.cat((x_cond, x_uncond), dim=0)
    t = torch.cat((t, t), dim=0)
```

---

## 4. ReStyle-TTS ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè©³ç´°

### 4.1 DCFG (Decoupled Classifier-Free Guidance) âœ… å®Ÿè£…æ¸ˆã¿

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `src/f5_tts/restyle/dcfg.py` - DCFGConfig, dcfg_combineé–¢æ•°
- `src/f5_tts/model/backbones/dit.py` - dcfg_inferãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ 
- `src/f5_tts/model/cfm.py` - sample()ã«use_dcfg, lambda_t, lambda_aè¿½åŠ 

#### æ•°å¼

**å¾“æ¥ã®CFG**:
```
fÌ‚_CFG = f_{a,t} + Î»_cfg Ã— (f_{a,t} - f_{âˆ…,âˆ…})
```

**DCFG**:
```
fÌ‚_DCFG = f_{âˆ…,t} + Î»_t Ã— (f_{âˆ…,t} - f_{âˆ…,âˆ…}) + Î»_a Ã— (f_{a,t} - f_{âˆ…,t})
```

- `f_{âˆ…,âˆ…}`: ç„¡æ¡ä»¶ï¼ˆéŸ³å£°ã‚‚ãƒ†ã‚­ã‚¹ãƒˆã‚‚ãƒ‰ãƒ­ãƒƒãƒ—ï¼‰
- `f_{âˆ…,t}`: ãƒ†ã‚­ã‚¹ãƒˆã®ã¿æ¡ä»¶ï¼ˆéŸ³å£°ãƒ‰ãƒ­ãƒƒãƒ—ï¼‰
- `f_{a,t}`: ãƒ•ãƒ«æ¡ä»¶ï¼ˆä¸¡æ–¹ã‚ã‚Šï¼‰
- `Î»_t`: ãƒ†ã‚­ã‚¹ãƒˆã‚¬ã‚¤ãƒ€ãƒ³ã‚¹å¼·åº¦ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2.0)
- `Î»_a`: å‚ç…§éŸ³å£°ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹å¼·åº¦ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.5)

#### ç­‰ä¾¡æ€§

`Î»_t = Î»_cfg`, `Î»_a = 1 + Î»_cfg` ã®ã¨ãã€DCFGã¯å¾“æ¥CFGã¨ç­‰ä¾¡ã€‚

#### è¨“ç·´æ™‚ã®å¤‰æ›´

```python
# 3æ®µéšã®ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ
drop_text_prob = 0.15      # ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ãƒ‰ãƒ­ãƒƒãƒ—
drop_audio_prob = 0.15     # éŸ³å£°ã®ã¿ãƒ‰ãƒ­ãƒƒãƒ—
drop_both_prob = 0.2       # ä¸¡æ–¹ãƒ‰ãƒ­ãƒƒãƒ—

# å„æ¡ä»¶ã®ç”Ÿæˆ
# 1. f_{âˆ…,âˆ…}: drop_audio=True, drop_text=True
# 2. f_{âˆ…,t}: drop_audio=True, drop_text=False
# 3. f_{a,t}: drop_audio=False, drop_text=False
```

### 4.2 Style LoRA âœ… å®Ÿè£…æ¸ˆã¿

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `src/f5_tts/restyle/style_lora.py` - StyleLoRAManager, StyleLoRAConfig
- `src/f5_tts/train/train_style_lora.py` - LoRAè¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- `src/f5_tts/configs/ReStyleTTS_Base.yaml` - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

#### LoRAè¨­å®š

```python
lora_config = {
    "r": 32,           # ãƒ©ãƒ³ã‚¯
    "lora_alpha": 64,  # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¿‚æ•°
    "target_modules": [
        "to_q", "to_k", "to_v", "to_out",  # Attention
        "ff.0", "ff.2",                     # FeedForward
    ],
    "lora_dropout": 0.0,
}
```

#### å­¦ç¿’ã™ã‚‹ã‚¹ã‚¿ã‚¤ãƒ«å±æ€§

| ã‚«ãƒ†ã‚´ãƒª | å±æ€§ |
|---------|------|
| Pitch | high, low |
| Energy | high, low |
| Emotion | angry, happy, sad, fear, disgusted, surprised |

#### è¨“ç·´ãƒ‡ãƒ¼ã‚¿

- VccmDataset (LibriTTS + æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ)
- è¨“ç·´æ™‚é–“: å„å±æ€§250æ™‚é–“

### 4.3 OLoRA Fusion (Orthogonal LoRA Fusion) ğŸ“‹ æœªå®Ÿè£…

**è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ«**: `src/f5_tts/restyle/olora_fusion.py`

#### ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

```python
def olora_fusion(lora_weights: List[Tensor], alphas: List[float]) -> Tensor:
    """
    è¤‡æ•°ã®LoRAã‚’ç›´äº¤å°„å½±ã—ã¦èåˆ

    Args:
        lora_weights: [Î”W_1, Î”W_2, ..., Î”W_N] å„LoRAã®é‡ã¿
        alphas: [Î±_1, Î±_2, ..., Î±_N] å„LoRAã®å¼·åº¦

    Returns:
        Î”W_fuse: èåˆã•ã‚ŒãŸLoRAé‡ã¿
    """
    N = len(lora_weights)
    D = lora_weights[0].numel()

    # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    V = torch.stack([w.flatten() for w in lora_weights])  # [N, D]

    # å„LoRAã‚’ä»–ã®LoRAã®éƒ¨åˆ†ç©ºé–“ã«ç›´äº¤å°„å½±
    orthogonalized = []
    for i in range(N):
        # V_{-i}: iç•ªç›®ä»¥å¤–ã®LoRA
        V_minus_i = torch.cat([V[:i], V[i+1:]], dim=0)  # [N-1, D]

        # å°„å½±è¡Œåˆ—: P_{-i} = V_{-i}^T @ pinv(V_{-i}^T)
        P_minus_i = V_minus_i.T @ torch.linalg.pinv(V_minus_i.T)

        # ç›´äº¤åŒ–: vÌ‚_i = (I - P_{-i}) @ v_i
        v_i = V[i]
        v_orth = v_i - P_minus_i @ v_i
        orthogonalized.append(v_orth)

    # é‡ã¿ä»˜ãåˆæˆ
    fused = sum(alpha * v for alpha, v in zip(alphas, orthogonalized))
    return fused.reshape(lora_weights[0].shape)
```

#### ç‰¹å¾´

- **é †åºéä¾å­˜**: å…¨ã¦ã®LoRAã‚’åŒæ™‚ã«ç›´äº¤åŒ–
- **ç–æ€§ä¿è¨¼**: N << D ã®ãŸã‚åŠ¹æœçš„ã«å¹²æ¸‰ã‚’é™¤å»
- **è¨“ç·´ä¸è¦**: æ¨è«–æ™‚ã«ã®ã¿é©ç”¨

### 4.4 TCO (Timbre Consistency Optimization) ğŸ“‹ æœªå®Ÿè£…

**è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ«**:
- `src/f5_tts/restyle/speaker_encoder.py` - WavLMè©±è€…ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼
- `src/f5_tts/restyle/tco.py` - TCOæå¤±å®Ÿè£…

#### ç›®çš„

DCFGã§å‚ç…§éŸ³å£°ã¸ã®ä¾å­˜ã‚’æ¸›ã‚‰ã™ã¨éŸ³è‰²ã®ä¸€è²«æ€§ãŒä½ä¸‹ã™ã‚‹å•é¡Œã‚’è£œå„Ÿã€‚

#### æ•°å¼

```python
# æ¨™æº–ã®Flow Matchingæå¤±
L_FM = E[(f_Î¸(x) - y)Â²]

# è©±è€…é¡ä¼¼åº¦å ±é…¬
r_t = speaker_similarity(generated_audio, reference_audio)

# EMAãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
b_t = Î¼ * b_{t-1} + (1 - Î¼) * r_t

# ã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸
A_t = r_t - b_t

# å ±é…¬é‡ã¿ä»˜ã‘
w_t = 1 + Î» * tanh(Î² * A_t)

# æœ€çµ‚æå¤±
L_total = w_t * L_FM
```

#### ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å€¤ | èª¬æ˜ |
|-----------|-----|------|
| Î» | 0.2 | å ±é…¬å¼·åº¦ |
| Î² | 5.0 | ã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸æ„Ÿåº¦ |
| Î¼ | 0.9 | EMAãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ  |

#### è©±è€…é¡ä¼¼åº¦è¨ˆç®—

```python
# WavLM base-plus-sv ã‚’ä½¿ç”¨
from transformers import WavLMForXVector

speaker_model = WavLMForXVector.from_pretrained("microsoft/wavlm-base-plus-sv")

def speaker_similarity(audio1, audio2):
    emb1 = speaker_model(audio1).embeddings
    emb2 = speaker_model(audio2).embeddings
    return F.cosine_similarity(emb1, emb2)
```

---

## 5. æ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

### 5.1 æ¨™æº–F5-TTSæ¨è«–

```
Reference Audio â†’ MelSpec â†’ CFM.sample() â†’ Vocoder â†’ Output Audio
                              â†‘
                           Text Input
```

### 5.2 ReStyle-TTSæ¨è«–

```
Reference Audio â†’ MelSpec â”€â”
                           â”‚
Text Input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â†’ DiT + Style LoRAs â†’ DCFG â†’ Vocoder â†’ Output
                           â”‚        â†‘
Style Controls â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   OLoRA Fusion
(pitch, energy, emotion)            â†‘
                              [LoRA_pitch, LoRA_energy, LoRA_emotion]
```

### 5.3 æ¨è«–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

```python
# DCFG ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
lambda_t = 2.0      # ãƒ†ã‚­ã‚¹ãƒˆã‚¬ã‚¤ãƒ€ãƒ³ã‚¹
lambda_a = 0.5      # å‚ç…§éŸ³å£°ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹

# Style LoRA ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
alpha_pitch = 0.0   # [-2.0, 2.0] è² ã§é€†åŠ¹æœ
alpha_energy = 0.0  # [-2.0, 2.0]
alpha_emotion = 0.0 # [0.0, 4.0] æ„Ÿæƒ…å¼·åº¦

# ODE ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
nfe_step = 32       # Number of Function Evaluations
ode_method = "euler"
```

---

## 6. è©•ä¾¡æŒ‡æ¨™

### 6.1 å®¢è¦³è©•ä¾¡

| æŒ‡æ¨™ | è¨ˆç®—æ–¹æ³• | ãƒ„ãƒ¼ãƒ« |
|------|----------|--------|
| WER | æ–‡å­—èª¤ã‚Šç‡ | Whisper-large-v3 |
| Spk-sv | è©±è€…é¡ä¼¼åº¦ | WavLM base-plus-sv |
| Pitch | åŸºæœ¬å‘¨æ³¢æ•° | Parselmouth |
| Energy | STFTæŒ¯å¹…ã®L2ãƒãƒ«ãƒ  | - |
| Emotion | æ„Ÿæƒ…åˆ†é¡ | Emotion2Vec |

### 6.2 ä¸»è¦³è©•ä¾¡

- **MOS-SA**: Mean Opinion Score - Style Accuracy (1-5ã‚¹ã‚±ãƒ¼ãƒ«)

---

## 7. å‚è€ƒæ–‡çŒ®

1. F5-TTS: Chen et al. (2024) - F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching
2. ReStyle-TTS: Li et al. (2026) - ReStyle-TTS: Relative and Continuous Style Control for Zero-Shot Speech Synthesis
3. LoRA: Hu et al. (2021) - LoRA: Low-Rank Adaptation of Large Language Models
4. Flow Matching: Lipman et al. (2022) - Flow Matching for Generative Modeling
