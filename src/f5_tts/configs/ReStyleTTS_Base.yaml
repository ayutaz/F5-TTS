# ReStyle-TTS Base Configuration
# Based on F5TTS_v1_Base with DCFG and Style LoRA support
#
# Usage:
#   # Full model training with DCFG
#   python -m f5_tts.train.train --config-name ReStyleTTS_Base
#
#   # Style LoRA training
#   python -m f5_tts.train.train_style_lora --config-name ReStyleTTS_Base \
#       style_attribute=pitch_high \
#       pretrained_checkpoint=path/to/base_model.pt

hydra:
  run:
    dir: ckpts/${model.name}_${model.mel_spec.mel_spec_type}_${model.tokenizer}_${datasets.name}/${now:%Y-%m-%d}/${now:%H-%M-%S}

# Dataset configuration
datasets:
  name: Emilia_ZH_EN
  batch_size_per_gpu: 38400  # frames per GPU
  batch_size_type: frame
  max_samples: 64
  num_workers: 16

# Optimizer configuration
optim:
  epochs: 11
  learning_rate: 7.5e-5
  lora_learning_rate: 1e-5  # LoRA訓練用の学習率
  num_warmup_updates: 20000
  grad_accumulation_steps: 1
  max_grad_norm: 1.0
  bnb_optimizer: False

# Model configuration
model:
  name: ReStyleTTS_Base
  tokenizer: pinyin
  tokenizer_path: null
  backbone: DiT
  arch:
    dim: 1024
    depth: 22
    heads: 16
    ff_mult: 2
    text_dim: 512
    text_mask_padding: True
    qk_norm: null
    conv_layers: 4
    pe_attn_head: null
    attn_backend: torch
    attn_mask_enabled: False
    checkpoint_activations: False
  mel_spec:
    target_sample_rate: 24000
    n_mel_channels: 100
    hop_length: 256
    win_length: 1024
    n_fft: 1024
    mel_spec_type: vocos
  vocoder:
    is_local: False
    local_path: null

# Checkpoint configuration
ckpts:
  logger: wandb
  log_samples: True
  save_per_updates: 50000
  keep_last_n_checkpoints: -1
  last_per_updates: 5000
  save_dir: ckpts/${model.name}_${model.mel_spec.mel_spec_type}_${model.tokenizer}_${datasets.name}

# ===========================================
# ReStyle-TTS Specific Configuration
# ===========================================

# DCFG (Decoupled Classifier-Free Guidance)
dcfg:
  enabled: True
  lambda_t: 2.0  # テキストガイダンス強度
  lambda_a: 0.5  # 参照音声ガイダンス強度
  # 訓練時ドロップアウト確率
  # (Phase 1ではCFMのデフォルト値を使用)
  # audio_only_drop: 0.15
  # text_only_drop: 0.15
  # both_drop: 0.2

# Style LoRA configuration
lora:
  rank: 32
  alpha: 64
  target_modules:
    - to_q
    - to_k
    - to_v
    - to_out.0
    - ff.ff.0
    - ff.ff.2
  dropout: 0.0
  bias: none

# Style attribute for LoRA training (set via CLI)
# Available: pitch_high, pitch_low, energy_high, energy_low,
#            angry, happy, sad, fear, disgusted, surprised
style_attribute: null

# Pretrained checkpoint path for LoRA training
pretrained_checkpoint: null

# Style attribute ranges for inference
style_ranges:
  pitch:
    min: -2.0
    max: 2.0
    default: 0.0
  energy:
    min: -2.0
    max: 2.0
    default: 0.0
  emotion:
    min: 0.0
    max: 4.0
    default: 1.0
