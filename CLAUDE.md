# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is F5-TTS extended with **ReStyle-TTS** capabilities for continuous and reference-relative style control in zero-shot speech synthesis.

Based on:
- F5-TTS: Flow matching based TTS (original repository)
- ReStyle-TTS: arXiv:2601.03632 - Relative and Continuous Style Control

## Implementation Status

| Phase | Feature | Status |
|-------|---------|--------|
| 1 | DCFG (Decoupled CFG) | âœ… å®Œäº† |
| 2 | Style LoRA | âœ… å®Œäº† |
| 3 | OLoRA Fusion | âœ… å®Œäº† |
| 4 | TCO | âœ… å®Œäº† |
| 5 | æŽ¨è«–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ | ðŸ“‹ æœªç€æ‰‹ |

è©³ç´°ã¯ `docs/IMPLEMENTATION_PLAN.md` ã‚’å‚ç…§ã€‚

## Build & Run Commands

```bash
# Install dependencies (using uv)
uv sync

# Or using pip
pip install -e .

# Run tests
uv run pytest tests/ -v

# Training (Hydra config)
python src/f5_tts/train/train.py --config-name F5TTS_v1_Base

# Style LoRA training
python -m f5_tts.train.train_style_lora --config-name ReStyleTTS_Base \
    style_attribute=pitch_high \
    pretrained_checkpoint=path/to/base_model.pt

# Inference CLI
python src/f5_tts/infer/infer_cli.py \
    --model F5TTS_v1_Base \
    --ref_audio path/to/ref.wav \
    --ref_text "reference text" \
    --gen_text "text to generate"

# Gradio UI
python src/f5_tts/infer/infer_gradio.py
```

## Architecture Overview

### F5-TTS Base Model
```
Input: Reference Audio + Text
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mel Spectrogram Extraction â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DiT (Diffusion Transformer)â”‚  â† 22 layers, dim=1024
â”‚  - TextEmbedding            â”‚
â”‚  - InputEmbedding           â”‚
â”‚  - DiTBlock Ã— 22            â”‚
â”‚    - AdaLayerNorm           â”‚
â”‚    - Attention (Q,K,V,Out)  â”‚
â”‚    - FeedForward            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Flow Matching (ODE Solver) â”‚  â† torchdiffeq.odeint
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vocoder (Vocos/BigVGAN)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
Output: Generated Audio
```

### ReStyle-TTS Extensions

1. **DCFG (Decoupled CFG)** âœ…: Separate text/reference guidance
2. **Style LoRA** âœ…: Attribute-specific adapters (pitch, energy, emotions)
3. **OLoRA Fusion** âœ…: Orthogonal multi-LoRA composition
4. **TCO** âœ…: Timbre consistency optimization with speaker similarity reward

## Key Files

### Core Model
- `src/f5_tts/model/cfm.py` - CFM class, sample() with CFG/DCFG
- `src/f5_tts/model/backbones/dit.py` - DiT transformer (dcfg_inferå¯¾å¿œæ¸ˆã¿)
- `src/f5_tts/model/modules.py` - Attention, FeedForward, DiTBlock
- `src/f5_tts/model/trainer.py` - Training loop

### ReStyle-TTS Extensions âœ…
- `src/f5_tts/restyle/__init__.py` - ReStyleãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
- `src/f5_tts/restyle/dcfg.py` - DCFGå®Ÿè£… (DCFGConfig, dcfg_combine)
- `src/f5_tts/restyle/style_lora.py` - Style LoRAç®¡ç† (StyleLoRAManager + OLoRAçµ±åˆ)
- `src/f5_tts/restyle/olora_fusion.py` - OLoRAç›´äº¤èžåˆ (OLoRAFusion, fuse_lora_weights)
- `src/f5_tts/restyle/speaker_encoder.py` - WavLMè©±è€…ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ (SpeakerEncoder)
- `src/f5_tts/restyle/tco.py` - TCOæå¤± (TCOLoss, TCOWeightComputer)
- `src/f5_tts/train/train_style_lora.py` - LoRAè¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### Inference
- `src/f5_tts/infer/utils_infer.py` - Inference utilities
- `src/f5_tts/api.py` - High-level API

### Config
- `src/f5_tts/configs/ReStyleTTS_Base.yaml` - ReStyle-TTSè¨­å®š
- `src/f5_tts/configs/*.yaml` - ãã®ä»–Hydra configs

### Tests
- `tests/test_dcfg.py` - DCFGãƒ†ã‚¹ãƒˆ (16ãƒ†ã‚¹ãƒˆ)
- `tests/test_style_lora.py` - Style LoRAãƒ†ã‚¹ãƒˆ (21ãƒ†ã‚¹ãƒˆ)
- `tests/test_olora_fusion.py` - OLoRA Fusionãƒ†ã‚¹ãƒˆ (30ãƒ†ã‚¹ãƒˆ)
- `tests/test_tco.py` - TCOãƒ†ã‚¹ãƒˆ (31ãƒ†ã‚¹ãƒˆ)

## DCFG Implementation âœ…

Location: `cfm.py`, `dit.py`, `restyle/dcfg.py`

```python
# DCFG formula (implemented)
fÌ‚ = f_{âˆ…,t} + Î»_t(f_{âˆ…,t} - f_{âˆ…,âˆ…}) + Î»_a(f_{a,t} - f_{âˆ…,t})
# Requires 3 forward passes: uncond, text-only, full-cond
# Default: Î»_t=2.0, Î»_a=0.5

# Usage
from f5_tts.model.cfm import CFM

output, _ = model.sample(
    cond, text, duration,
    use_dcfg=True,
    lambda_t=2.0,
    lambda_a=0.5,
)
```

## Style LoRA Implementation âœ…

Location: `restyle/style_lora.py`, `train/train_style_lora.py`

```python
# Style LoRA config
lora_config = {
    "rank": 32,
    "alpha": 64,
    "target_modules": ["to_q", "to_k", "to_v", "to_out.0", "ff.ff.0", "ff.ff.2"],
    "dropout": 0.0,
}

# Available style attributes
STYLE_ATTRIBUTES = {
    "pitch_high", "pitch_low",       # ãƒ”ãƒƒãƒ
    "energy_high", "energy_low",     # ã‚¨ãƒãƒ«ã‚®ãƒ¼
    "angry", "happy", "sad",         # æ„Ÿæƒ…
    "fear", "disgusted", "surprised"
}

# Usage
from f5_tts.restyle import StyleLoRAManager

manager = StyleLoRAManager(model.transformer)
manager.load_lora("pitch_high", "path/to/pitch_high.safetensors")

with manager.apply_styles({"pitch_high": 1.0}):
    output = model.sample(...)
```

## OLoRA Fusion Implementation âœ…

Location: `restyle/olora_fusion.py`, `restyle/style_lora.py`

```python
# Orthogonal projection formula
vÌ‚_i = (I - P_{-i}) @ v_i  # where P_{-i} = V_{-i}^T @ pinv(V_{-i}^T)
Î”W_fuse = Î£ Î±_i * Î”Å´_i   # weighted sum of orthogonalized LoRAs

# Usage with StyleLoRAManager
from f5_tts.restyle import StyleLoRAManager, OLoRAConfig

manager = StyleLoRAManager(model.transformer, olora_config=OLoRAConfig())
manager.load_lora("pitch_high", "path/to/pitch_high.safetensors")
manager.load_lora("angry", "path/to/angry.safetensors")

# Apply multiple styles with OLoRA fusion (default)
with manager.apply_styles({"pitch_high": 1.0, "angry": 0.5}, use_olora=True):
    output = model.sample(...)

# Low-level API
from f5_tts.restyle import OLoRAFusion

fusion = OLoRAFusion()
fusion.add_lora("pitch_high", pitch_high_state_dict)
fusion.add_lora("angry", angry_state_dict)
interference = fusion.compute_interference("pitch_high", "angry")  # 0.0-1.0
fused = fusion.fuse({"pitch_high": 1.0, "angry": 0.5})
```

## TCO Implementation âœ…

Location: `restyle/tco.py`, `restyle/speaker_encoder.py`

```python
# Advantage-weighted flow matching loss formula
w_t = 1 + Î» * tanh(Î² * A_t)
A_t = r_t - b_t  # advantage = reward - baseline
L_total = w_t * L_FM
# Î»=0.2, Î²=5.0, Î¼=0.9 (EMA baseline)

# Usage
from f5_tts.restyle import TCOLoss, TCOConfig, SpeakerEncoder

# Create TCO loss
config = TCOConfig(lambda_reward=0.2, beta=5.0, mu=0.9)
tco_loss = TCOLoss(config=config)

# In training loop
base_loss = compute_flow_matching_loss(...)
weighted_loss, metrics = tco_loss(
    base_loss,
    generated_audio=gen_audio,
    reference_audio=ref_audio,
)

# Or with pre-computed reward
from f5_tts.restyle import compute_speaker_similarity
reward = compute_speaker_similarity(gen_audio, ref_audio)
weighted_loss, metrics = tco_loss(base_loss, reward=reward)

# Metrics include:
# - tco_reward_mean: average speaker similarity
# - tco_baseline: EMA baseline
# - tco_weight_mean: average loss weight
```

## Development Notes

- Use `uv` for dependency management (`uv sync`, `uv add`)
- Use `accelerate` for multi-GPU training
- EMA model is used for inference
- Checkpoints saved as `.safetensors` or `.pt`
- Audio: 24kHz, 100 mel channels, hop_length=256
- Python version: >=3.10, <3.13 (due to av package compatibility)
- Tests: `uv run pytest tests/ -v`

## Documentation

- `docs/ROADMAP.md` - å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒžãƒƒãƒ—
- `docs/IMPLEMENTATION_PLAN.md` - è©³ç´°å®Ÿè£…è¨ˆç”»
- `docs/RESTYLE_TTS_ARCHITECTURE.md` - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©³ç´°
